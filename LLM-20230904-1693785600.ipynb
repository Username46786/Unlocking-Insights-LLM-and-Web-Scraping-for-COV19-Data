{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Embark on a COVID-19 Data Quest: Web Scraping and Regex Adventure LLM !**\n",
    "\n",
    "Estimated time needed: **30 minutes**\n",
    "\n",
    "Get ready to embark on a thrilling web scraping adventure with a COVID-19 twist in this guided project! We're diving headfirst into the fascinating world of data extraction while having a blast. As we navigate the web, you'll master the art of using regular expressions (regex) to capture elusive COVID-19 data hidden in the depths of websites. We'll turn complex HTML and text documents into our treasure maps, and regex will be our trusty compass to find the data gems we seek. It's like being a digital detective, deciphering clues and unearthing vital pandemic statistics.\n",
    "\n",
    "But that's not all! In the final act of our data journey, we'll harness the power of Language Model (LLM) technology to summarize and make sense of the wealth of data we've collected. By employing an LLM, we'll distill our findings into concise, informative summaries, providing valuable insights into the pandemic landscape.\n",
    "\n",
    "By the end of this project, you'll not only be a web scraping wizard but also have a great story to tell about your epic COVID-19 data quest. So, put on your virtual explorer hat, and let's dive into the world of web scraping, regex, and LLM-driven data analysis with excitement and curiosity!\n",
    "<!-- \n",
    "<p style='color: red'>Give the learner a preview of the problem/story that [Subject of the Lab] will end up solving.</p>\n",
    "\n",
    "Include an image to enhance the appeal of your guided project.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/template/images/iris.jpeg\" width=\"600px\" alt=\"iris image\"/>\n",
    "\n",
    "<font color=gray>*Image Resource* :</font> <a href=\"\">Somewhere</a> -->\n",
    "\n",
    "\n",
    "IBM has a special offer for watsonx.ai, a studio for new foundation models, generative AI and machine learning. To take advantage of this offer visit\n",
    "    \n",
    " <a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX0TUREN4123-2023-01-01&context=wx&apps=data_science_experience%2Cwatson_data_platform%2Ccos\">watsonx.ai</a>   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0TUREN/images/web_scrap_regex.jpeg\" height=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#What-is-Web-scrapping.?\">What is Web- scrapping.?</a>\n",
    "    </li>\n",
    "    <li><a href=\"#Pre-Processing-COVID-19-Data\">Pre-Processing COVID-19 Data</a></li>\n",
    "    <ol>\n",
    "            <li><a href=\"#Loading-the HTML-Data-of-COVID-19-from-Worldometers\">Loading the HTML Data of COVID-19 from Worldometers</a></li>\n",
    "            <li><a href=\"#Preprocessing-of-Columns\">Preprocessing of Columns</a></li>\n",
    "    </ol>\n",
    "    <li><a href=\"#Regular-Expressions\">Regular Expressions</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Exercises\">Exercises</a>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    " - Web scrapping.\n",
    " - HTML Text parsing\n",
    " - RegEx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`Beautiful Soup`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for web scrapping and HTML parsing.\n",
    "<!-- *   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `%pip` in the code cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.6/761.6 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers) (2.29.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: fsspec in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers, safetensors, regex, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 huggingface-hub-0.16.4 regex-2023.12.25 safetensors-0.4.1 tokenizers-0.13.3 transformers-4.30.2\n",
      "Collecting tokenizer\n",
      "  Downloading tokenizer-3.4.3-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizer\n",
      "Successfully installed tokenizer-3.4.3\n",
      "Collecting hugchat\n",
      "  Downloading hugchat-0.3.8-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from hugchat) (2.29.0)\n",
      "Requirement already satisfied: requests-toolbelt in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from hugchat) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->hugchat) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->hugchat) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->hugchat) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->hugchat) (2023.5.7)\n",
      "Installing collected packages: hugchat\n",
      "Successfully installed hugchat-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install tokenizer\n",
    "!pip install hugchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from transformers import pipeline\n",
    "import getpass\n",
    "from hugchat import hugchat\n",
    "from hugchat.login import Login\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_columns', 1000, 'display.width', 1000, 'display.max_rows',1000)\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Web scraping.?\n",
    "\n",
    "Web scraping in Python involves extracting data from websites, and there are several methods and techniques you can use to achieve this goal. \n",
    "Here are some of the different methods of web scraping in Python:\n",
    "\n",
    "1. Using BeautifulSoup and Requests:\n",
    "This is one of the most common methods for web scraping in Python.\n",
    "The requests library is used to fetch the HTML content of web pages, and the BeautifulSoup library is used to parse and extract data from the HTML.\n",
    "This method is suitable for static web pages with well-structured HTML.\n",
    "Using Selenium:\n",
    "\n",
    "2. Selenium: It is a web automation tool that allows you to control a web browser programmatically.\n",
    "It can be used for web scraping dynamic websites that rely heavily on JavaScript, as it can interact with the page as a human user would.\n",
    "Selenium is often used when other methods fail to retrieve the data you need.\n",
    "Scrapy Framework:\n",
    "\n",
    "3. Scrapy: It is a powerful and flexible web scraping framework for Python.\n",
    "It provides a high-level framework for defining how to extract data from websites, follow links, and store the data.\n",
    "Scrapy is well-suited for more complex web scraping projects and can handle crawling multiple pages and websites.\n",
    "\n",
    "4. APIs: Many websites offer APIs (Application Programming Interfaces) that allow you to access and retrieve data in a structured format, such as JSON or XML.\n",
    "Instead of scraping HTML, you can make API requests to fetch the data directly.\n",
    "Using APIs is often more efficient and reliable than web scraping HTML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0TUREN/images/web_scrap_tree.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing COVID-19 Data\n",
    "In this section, we will process a covid-19 data from worldometers.info, extracting all the coutry's details like critical cases, recovered cases. and also do preprocessing for each columns as needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the HTML Data of COVID-19 from Worldometers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the below code as i have already loaded data into the text file we are using that \n",
    "But you can run using the code below.\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_covid_data():\n",
    "    url = 'https://www.worldometers.info/coronavirus/'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        global zzz\n",
    "        zzz = response.content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', id='main_table_countries_today')\n",
    "        rows = table.find_all('tr')      \n",
    "        return rows\n",
    "\n",
    "    else:\n",
    "        print('Failed to fetch data. Status code:', response.status_code)\n",
    "        return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    covid_data = scrape_covid_data()\n",
    "    if covid_data is not None:\n",
    "        print(covid_data)\n",
    "        \n",
    "# For Writing text file\n",
    "file1 = open(\"web_scrape_covid_text.txt\",\"w\")\n",
    "file1.write(str(covid_data))\n",
    "file1.close()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-26 19:54:52--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0TUREN/data/web_scrape_covid_text.txt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 351482 (343K) [text/plain]\n",
      "Saving to: ‘web_scrape_covid_text.txt’\n",
      "\n",
      "web_scrape_covid_te 100%[===================>] 343.24K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2023-12-26 19:54:52 (42.7 MB/s) - ‘web_scrape_covid_text.txt’ saved [351482/351482]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0TUREN/data/web_scrape_covid_text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read file using Open function. Which returns String of HTML file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('web_scrape_covid_text.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we have created text file from our scrape data so we have to convert it into html parser to access particular rows using tr (table row) tag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_soup = bs(text, 'html.parser')\n",
    "new_rows = new_soup.find_all('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The country column contains '\\n' in it's rows for some values, therefore we are replacing '\\n' with a null string \"\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows=new_rows\n",
    "country_data = []\n",
    "for row in rows[1:]:\n",
    "            columns = row.find_all('td')\n",
    "            country = columns[1].text.replace(\"\\n\",\"\")\n",
    "            total_cases = columns[2].text\n",
    "            new_cases = columns[3].text.strip()\n",
    "            total_deaths = columns[4].text\n",
    "            new_deaths = columns[5].text\n",
    "            total_recovered = columns[6].text\n",
    "            active_cases = columns[8].text\n",
    "            critical_cases = columns[9].text\n",
    "            total_tests = columns[12].text\n",
    "            country_data.append({\n",
    "                'Country': country,\n",
    "                'Total Cases': total_cases,\n",
    "                'New Cases': new_cases,\n",
    "                'Total Deaths': total_deaths,\n",
    "                'New Deaths': new_deaths,\n",
    "                'Total Recovered': total_recovered,\n",
    "                'Active Cases': active_cases,\n",
    "                'Critical Cases': critical_cases,\n",
    "                'Total Tests': total_tests\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "covid_data=pd.DataFrame(country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Country  Total Cases New Cases Total Deaths New Deaths  \\\n",
      "0    North America  127,789,069              1,643,436              \n",
      "1             Asia  220,566,581              1,549,056              \n",
      "2           Europe  249,832,824              2,069,833              \n",
      "3    South America   68,958,962              1,360,127              \n",
      "4          Oceania   14,620,570                 30,157              \n",
      "..             ...          ...       ...          ...        ...   \n",
      "242         Total:   68,958,962              1,360,127              \n",
      "243         Total:   14,620,570                 30,157              \n",
      "244         Total:   12,836,690                258,825              \n",
      "245         Total:          721                     15              \n",
      "246         Total:  694,605,417         0    6,911,449          0   \n",
      "\n",
      "    Total Recovered Active Cases Critical Cases Total Tests  \n",
      "0       123,485,287    2,660,346          6,313              \n",
      "1       203,865,250   15,152,275         15,149              \n",
      "2       245,958,596    1,804,395          5,467              \n",
      "3        66,514,352    1,084,483         10,078              \n",
      "4        14,485,372      105,041             49              \n",
      "..              ...          ...            ...         ...  \n",
      "242      66,514,352    1,084,483         10,078              \n",
      "243      14,485,372      105,041             49              \n",
      "244      12,088,194      489,671            547              \n",
      "245             706            0              0              \n",
      "246     666,397,757   21,296,211         37,603              \n",
      "\n",
      "[247 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we can see New cases and New death columns has null values so, we will remove that two columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covid_data.drop(['New Cases','New Deaths','Total Tests'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Recovered</th>\n",
       "      <th>Active Cases</th>\n",
       "      <th>Critical Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North America</td>\n",
       "      <td>127,789,069</td>\n",
       "      <td>1,643,436</td>\n",
       "      <td>123,485,287</td>\n",
       "      <td>2,660,346</td>\n",
       "      <td>6,313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia</td>\n",
       "      <td>220,566,581</td>\n",
       "      <td>1,549,056</td>\n",
       "      <td>203,865,250</td>\n",
       "      <td>15,152,275</td>\n",
       "      <td>15,149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>249,832,824</td>\n",
       "      <td>2,069,833</td>\n",
       "      <td>245,958,596</td>\n",
       "      <td>1,804,395</td>\n",
       "      <td>5,467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South America</td>\n",
       "      <td>68,958,962</td>\n",
       "      <td>1,360,127</td>\n",
       "      <td>66,514,352</td>\n",
       "      <td>1,084,483</td>\n",
       "      <td>10,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oceania</td>\n",
       "      <td>14,620,570</td>\n",
       "      <td>30,157</td>\n",
       "      <td>14,485,372</td>\n",
       "      <td>105,041</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  Total Cases Total Deaths Total Recovered Active Cases  \\\n",
       "0  North America  127,789,069    1,643,436     123,485,287    2,660,346   \n",
       "1           Asia  220,566,581    1,549,056     203,865,250   15,152,275   \n",
       "2         Europe  249,832,824    2,069,833     245,958,596    1,804,395   \n",
       "3  South America   68,958,962    1,360,127      66,514,352    1,084,483   \n",
       "4        Oceania   14,620,570       30,157      14,485,372      105,041   \n",
       "\n",
       "  Critical Cases  \n",
       "0          6,313  \n",
       "1         15,149  \n",
       "2          5,467  \n",
       "3         10,078  \n",
       "4             49  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex, short for Regular Expression, is a powerful tool used in computer science and programming for pattern matching within strings. It provides a concise and flexible way to search, match, and manipulate text based on specific patterns. Regex patterns are composed of a combination of characters and metacharacters that define the search criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0TUREN/images/regex_img.jpg\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some common uses of regular expressions:\n",
    "\n",
    "1) Pattern Matching: You can use regex to find and extract text that matches a specific pattern. For example, searching for all email addresses in a text document.\n",
    "\n",
    "2) Validation: Regex can be used to validate input data. For instance, checking if a user-provided string conforms to a certain format, like a phone number or postal code.\n",
    "\n",
    "3) Data Extraction: It's useful for extracting specific information from a larger dataset. For instance, parsing log files to extract relevant data.\n",
    "\n",
    "4) Text Manipulation: Regex can be used to replace or modify text based on a pattern. For example, finding and replacing all occurrences of a word in a document.\n",
    "\n",
    "Regex patterns consist of regular characters (like letters and numbers) and metacharacters (like *, ., ^, $, and many others), each with a special meaning. Here are some examples:\n",
    "\n",
    "    . matches any single character except a newline.\n",
    "    * matches zero or more occurrences of the preceding character or group.\n",
    "    + matches one or more occurrences of the preceding character or group.\n",
    "    ? matches zero or one occurrence of the preceding character or group.\n",
    "    [] defines a character class, matching any character within the brackets.\n",
    "    () groups characters together to form sub-patterns.\n",
    "For example, the regex pattern ^abc\\d+ would match any string that starts with \"abc\" followed by one or more digits.\n",
    "\n",
    "Different programming languages and text editors often have their own implementations of regular expressions, but the basic syntax and concepts remain fairly consistent across most of them.\n",
    "\n",
    "Regex can be quite powerful, but it can also be complex and challenging to master. It's important to be cautious when using regular expressions, as poorly designed patterns can lead to unexpected results or performance issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - Find a Countries which names starts with C.?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def startswith(column,letter):\n",
    "    List1=[]\n",
    "    for i in column:\n",
    "        if i[:1] == letter:\n",
    "            List1.append(i)\n",
    "    return List1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Colombia',\n",
       " 'Chile',\n",
       " 'Canada',\n",
       " 'Czechia',\n",
       " 'Croatia',\n",
       " 'Costa Rica',\n",
       " 'Cuba',\n",
       " 'Cyprus',\n",
       " 'Cambodia',\n",
       " 'Cameroon',\n",
       " 'Channel Islands',\n",
       " 'Cabo Verde',\n",
       " 'Curaçao',\n",
       " 'Cayman Islands',\n",
       " 'Congo',\n",
       " 'CAR',\n",
       " 'Caribbean Netherlands',\n",
       " 'Comoros',\n",
       " 'Chad',\n",
       " 'Cook Islands',\n",
       " 'China']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startswith(covid_data['Country'],\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - Find a Countries which names starts with and ends with A.?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def startendwith(column):\n",
    "    r = re.compile(\"A|a.*A|a\")\n",
    "    newlist = list(filter(r.match, column)) # Read Note below\n",
    "    return(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asia',\n",
       " 'Africa',\n",
       " 'Australia',\n",
       " 'Argentina',\n",
       " 'Austria',\n",
       " 'Azerbaijan',\n",
       " 'Armenia',\n",
       " 'Albania',\n",
       " 'Algeria',\n",
       " 'Afghanistan',\n",
       " 'Angola',\n",
       " 'Andorra',\n",
       " 'Aruba',\n",
       " 'Antigua and Barbuda',\n",
       " 'Anguilla']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startendwith(covid_data['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 - Find a country which name has 2 \"I\" in it.?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def countofletter2i(column):\n",
    "     # Define a regex pattern to find \"ii\"\n",
    "    pattern = r'(?:i[^i]*i)'\n",
    "    # Use str.contains with regex=True to find rows containing \"ii\"\n",
    "    filtered_df = covid_data[covid_data[column].str.contains(pattern, regex=True)]\n",
    "    return(covid_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      North America\n",
       "1               Asia\n",
       "2             Europe\n",
       "3      South America\n",
       "4            Oceania\n",
       "           ...      \n",
       "242           Total:\n",
       "243           Total:\n",
       "244           Total:\n",
       "245           Total:\n",
       "246           Total:\n",
       "Name: Country, Length: 247, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countofletter2i('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to scrape another page of worldometer. Which has data related to population of all the coutries across the world.\n",
    "- ```https://www.worldometers.info/world-population/```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current population ofIndiais1,434,983,349as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.India2023 population is estimated at1,428,627,663people at mid year.Indiapopulation is equivalent to17.76%of thetotal world population.Indiaranks number1in the list ofcountries (and dependencies) by population.The population density in India is 481 per Km2(1,244 people per mi2).The totallandarea is 2,973,190 Km2 (1,147,955 sq. miles)36.3 %of the population isurban(518,239,122 people in 2023)Themedian agein India is28.2 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).\n",
      "The current population ofIndiais1,434,983,349as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.India2023 population is estimated at1,428,627,663people at mid year.Indiapopulation is equivalent to17.76%of thetotal world population.Indiaranks number1in the list ofcountries (and dependencies) by population.The population density in India is 481 per Km2(1,244 people per mi2).The totallandarea is 2,973,190 Km2 (1,147,955 sq. miles)36.3 %of the population isurban(518,239,122 people in 2023)Themedian agein India is28.2 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).The current population ofAfghanistanis42,785,170as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.Afghanistan2023 population is estimated at42,239,854people at mid year.Afghanistanpopulation is equivalent to0.53%of thetotal world population.Afghanistanranks number36in the list ofcountries (and dependencies) by population.The population density in Afghanistan is 65 per Km2(168 people per mi2).The totallandarea is 652,860 Km2 (252,071 sq. miles)25.9 %of the population isurban(10,948,055 people in 2023)Themedian agein Afghanistan is17.0 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).\n",
      "The current population ofIndiais1,434,983,349as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.India2023 population is estimated at1,428,627,663people at mid year.Indiapopulation is equivalent to17.76%of thetotal world population.Indiaranks number1in the list ofcountries (and dependencies) by population.The population density in India is 481 per Km2(1,244 people per mi2).The totallandarea is 2,973,190 Km2 (1,147,955 sq. miles)36.3 %of the population isurban(518,239,122 people in 2023)Themedian agein India is28.2 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).The current population ofAfghanistanis42,785,170as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.Afghanistan2023 population is estimated at42,239,854people at mid year.Afghanistanpopulation is equivalent to0.53%of thetotal world population.Afghanistanranks number36in the list ofcountries (and dependencies) by population.The population density in Afghanistan is 65 per Km2(168 people per mi2).The totallandarea is 652,860 Km2 (252,071 sq. miles)25.9 %of the population isurban(10,948,055 people in 2023)Themedian agein Afghanistan is17.0 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).The current population ofthe United States of Americais340,880,724as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.the United States2023 population is estimated at339,996,563people at mid year.the United Statespopulation is equivalent to4.23%of thetotal world population.the U.S.A.ranks number3in the list ofcountries (and dependencies) by population.The population density in the United States is 37 per Km2(96 people per mi2).The totallandarea is 9,147,420 Km2 (3,531,837 sq. miles)82.9 %of the population isurban(281,984,165 people in 2023)Themedian agein the United States is38.1 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).\n",
      "The current population ofIndiais1,434,983,349as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.India2023 population is estimated at1,428,627,663people at mid year.Indiapopulation is equivalent to17.76%of thetotal world population.Indiaranks number1in the list ofcountries (and dependencies) by population.The population density in India is 481 per Km2(1,244 people per mi2).The totallandarea is 2,973,190 Km2 (1,147,955 sq. miles)36.3 %of the population isurban(518,239,122 people in 2023)Themedian agein India is28.2 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).The current population ofAfghanistanis42,785,170as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.Afghanistan2023 population is estimated at42,239,854people at mid year.Afghanistanpopulation is equivalent to0.53%of thetotal world population.Afghanistanranks number36in the list ofcountries (and dependencies) by population.The population density in Afghanistan is 65 per Km2(168 people per mi2).The totallandarea is 652,860 Km2 (252,071 sq. miles)25.9 %of the population isurban(10,948,055 people in 2023)Themedian agein Afghanistan is17.0 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).The current population ofthe United States of Americais340,880,724as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.the United States2023 population is estimated at339,996,563people at mid year.the United Statespopulation is equivalent to4.23%of thetotal world population.the U.S.A.ranks number3in the list ofcountries (and dependencies) by population.The population density in the United States is 37 per Km2(96 people per mi2).The totallandarea is 9,147,420 Km2 (3,531,837 sq. miles)82.9 %of the population isurban(281,984,165 people in 2023)Themedian agein the United States is38.1 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).The current population ofChinais1,425,431,098as of Tuesday, December 26, 2023, based on Worldometer elaboration of the latest United Nations data1.China2023 population is estimated at1,425,671,352people at mid year.Chinapopulation is equivalent to17.72%of thetotal world population.Chinaranks number2in the list ofcountries (and dependencies) by population.The population density in China is 152 per Km2(393 people per mi2).The totallandarea is 9,388,211 Km2 (3,624,807 sq. miles)65.0 %of the population isurban(926,375,811 people in 2023)Themedian agein China is39.0 years.1. Updated on July 16, 2023 with the latest July 2023-July 2024 estimates from the United Nations, Department of Economic and Social Affairs, Population Division.World Population Prospects: The 2022 Revision. (Medium-fertility variant).\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_india_population(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the element containing the population information\n",
    "        population_element = soup.find('div', {'class': 'col-md-8 country-pop-description'})\n",
    "\n",
    "        # Extract the population text\n",
    "        population_text = population_element.get_text(strip=True)\n",
    "\n",
    "        return population_text\n",
    "    else:\n",
    "        print('Failed to fetch data. Status code:', response.status_code)\n",
    "        return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    population_info=\"\"\n",
    "    for country in ['india','afghanistan','us','china']:\n",
    "        url = 'https://www.worldometers.info/world-population/'+country+'-population/'\n",
    "        population_info=population_info+scrape_india_population(url)\n",
    "\n",
    "        if population_info:\n",
    "            print(population_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Large language model LLM\n",
    "\n",
    "Now the final act of our data journey, we'll harness the power of Language Model (LLM) technology to summarize and make sense of the wealth of data we've collected. By employing an LLM, we'll distill our findings into concise, informative summaries, providing valuable insights into the pandemic landscape.\n",
    "\n",
    "## 🤗 Hugging Face: Your Gateway to State-of-the-Art NLP\n",
    "Hugging Face is a powerful library that opens the gateway to cutting-edge Natural Language Processing (NLP). It offers a wide array of pre-trained language models designed for various NLP tasks, such as text classification and sentiment analysis. These models are built on advanced deep learning algorithms and have undergone fine-tuning for specific NLP applications, eliminating the need to train models from scratch.\n",
    "\n",
    "### Why Hugging Face?\n",
    "- **Standardization:** Hugging Face addresses the challenges of transfer learning by providing a standardized approach. It allows seamless integration of pre-trained models trained using different libraries, such as TensorFlow and PyTorch.\n",
    "\n",
    "- **Easy-to-Use:** The Hugging Face library offers a user-friendly interface, making it accessible to both beginners and experts.\n",
    "- **Diverse Selection:** Hugging Face provides a rich selection of pre-trained models, ranging from traditional machine learning algorithms to cutting-edge transformers.\n",
    "\n",
    " We will use the Hugging Face's own LLM chat bot **Hugging Chat** to generate summery.\n",
    "\n",
    "Before you begin, make sure to sign up for a Hugging Face account to gain access to their API and leverage their language models. You can easily sign up for an account by visiting the [Hugging Face Website](https://huggingface.co/join)\n",
    "\n",
    "We create a chatbot object ```chatbot```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your email jcontrerasgcca18@gmail.com\n",
      "Enter your password ········\n"
     ]
    }
   ],
   "source": [
    "# login to Hugging Face\n",
    "email = input(\"Enter your email\")\n",
    "password = getpass.getpass('Enter your password')\n",
    "sign = Login(email, password)\n",
    "cookies = sign.login()\n",
    "\n",
    "# create a chatbot connection using the HuggingChat API\n",
    "chatbot = hugchat.ChatBot(cookies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store the chat history in the list ```chat_history``` for  the messege to the chat bot will be \"Can you tell me about this \" plus our data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store chat history\n",
    "chat_history = []\n",
    "\n",
    "#  input message containing population_info\n",
    "message = \"Can you tell me about this \" + population_info\n",
    "\n",
    "# Append the message to the chat history list\n",
    "chat_history.append(message)\n",
    "\n",
    "# Join the chat history list into a single string with newline separators\n",
    "conv = \"\\n\".join(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the chatbot to generate a response based on the conversation history (conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here's a comparison of the populations of India, Afghanistan, the United States, and China based on the information provided:\n",
      "\n",
      "* India: 1,434,983,349 (mid-year estimate for 2023)\n",
      "* Afghanistan: 42,785,170 (mid-year estimate for 2023)\n",
      "* United States: 340,880,724 (mid-year estimate for 2023)\n",
      "* China: 1,425,431,098 (mid-year estimate for 2023)\n",
      "\n",
      "As we can see, India has the largest population among these four countries, followed by China, the United States, and then Afghanistan. In terms of percentage of the total world population, India accounts for 17.76%, China accounts for 17.72%, the United States accounts for 4.23%, and Afghanistan accounts for 0.53%.\n",
      "\n",
      "In terms of population density, China has the highest population density among these four countries, with 152 people per square kilometer, followed by India with 481 people per square kilometer, the United States with 37 people per square kilometer, and Afghanistan with 65 people per square kilometer.\n",
      "\n",
      "Finally, in terms of median age, the United States has the highest median age at 38.1 years, followed by China at 39.0 years, India at 28.2 years, and Afghanistan at 17.0 years.\n"
     ]
    }
   ],
   "source": [
    "ai_response = chatbot.chat(conv)\n",
    "\n",
    "# Print the AI-generated response\n",
    "print(ai_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the AI-generated response to the chat history for future reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_history.append(ai_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code will prompt you to ask more questions about your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to know more? Type 'out' to exit\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " out\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 1: expected str instance, Message found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77/497041857.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Join the chat history into a single string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Generate an AI response based on the conversation history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 1: expected str instance, Message found"
     ]
    }
   ],
   "source": [
    "# Initialize a flag variable to control the loop\n",
    "out = False\n",
    "\n",
    "# Start a loop to continue the conversation\n",
    "while out == False:\n",
    "    # Prompt the user to ask more questions or exit\n",
    "    print(\"Would you like to know more? Type 'out' to exit\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Get user input\n",
    "    prompt = input()\n",
    "    \n",
    "    # Join the chat history into a single string\n",
    "    conv = \"\\n\".join(chat_history)\n",
    "\n",
    "    # Generate an AI response based on the conversation history\n",
    "    ai_response = chatbot.chat(conv)\n",
    "    \n",
    "    # Print the AI-generated response\n",
    "    print(ai_response)\n",
    "    \n",
    "    # Append the user's input and AI response to the chat history\n",
    "    chat_history.append(prompt)\n",
    "    chat_history.append(ai_response)\n",
    "    \n",
    "    # Check if the user wants to exit the conversation\n",
    "    if prompt == \"out\":\n",
    "        print(\"Leaving\")\n",
    "        out = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Find the population of United States of America Using Regex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population of the United States of America: 340880724\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "import re\n",
    "\n",
    "# Define a regex pattern to match the population of the United States\n",
    "pattern = r\"population .* United States of Americais(\\d+,\\d+,\\d+)\"\n",
    "\n",
    "# Use re.search to find the population\n",
    "match = re.search(pattern, population_info)\n",
    "\n",
    "if match:\n",
    "    # Extract and print the population\n",
    "    population = match.group(1)\n",
    "    # Remove commas to get the actual number as an integer\n",
    "    population = int(population.replace(',', ''))\n",
    "    print(\"Population of the United States of America:\", population)\n",
    "else:\n",
    "    print(\"Population not found in the text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Find the landarea of India using Regex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Area of India: 2973190 Km2\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "import re\n",
    "pattern = r\"The totallandarea is (\\d+,\\d+,\\d+) Km2\"\n",
    "\n",
    "# Use re.search to find the land area\n",
    "match = re.search(pattern, population_info)\n",
    "\n",
    "if match:\n",
    "    # Extract and print the land area\n",
    "    land_area = match.group(1)\n",
    "    # Remove commas to get the actual number as an integer\n",
    "    land_area = int(land_area.replace(',', ''))\n",
    "    print(\"Land Area of India:\", land_area, \"Km2\")\n",
    "else:\n",
    "    print(\"Land Area of India not found in the text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Extract the median age in the China using Regex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Age in China: 39.0 years\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Define a regex pattern to match the median age in China\n",
    "pattern = r\"Themedian agein China is([\\d.]+) years\"\n",
    "\n",
    "# Use re.search to find the median age in China\n",
    "match = re.search(pattern, population_info)\n",
    "\n",
    "if match:\n",
    "    # Extract and print the median age in China\n",
    "    median_age = match.group(1)\n",
    "    print(\"Median Age in China:\", median_age, \"years\")\n",
    "else:\n",
    "    print(\"Median Age in China not found in the text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jigisha Barbhaya](https://www.linkedin.com/in/jigisha-barbhaya/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX0BMUEN2063-2022-01-01)\n",
    "> <i> As a data scientist in IBM, I have always been passionate about sharing my knowledge and helping others learn about the field. I believe that everyone should have the opportunity to learn about data science, regardless of their background or experience level. This belief has inspired me to become a learning content provider, creating and sharing educational materials that are accessible and engaging for everyone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contributor with Link](contributor_linl), Contributor No Link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-05-01|0.1|Shengkai|Create Lab Template|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
